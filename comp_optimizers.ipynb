{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:37:31.851377Z",
     "end_time": "2023-04-17T18:37:38.268604Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import BasePruner\n",
    "from inflation import BBI\n",
    "from torch.optim import Adam, Adagrad, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:37:38.280972Z",
     "end_time": "2023-04-17T18:37:38.476777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(32*7*7, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:11:14.356554Z",
     "end_time": "2023-04-17T19:11:14.376649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def hyperparameter_search(trial: optuna.trial.Trial, optimizer):\n",
    "    model = Net()\n",
    "    learning_rates = trial.suggest_categorical(\"lr\", [0.01, 0.001, 0.0001])\n",
    "    batch_sizes = trial.suggest_categorical(\"bs\",[32, 64, 128])\n",
    "    if isinstance(optimizer(model.parameters(), lr=0.01), BBI):\n",
    "        delta_E = trial.suggest_categorical(\"delta_e\", [0, 0.1, 0.5, 1, 2])\n",
    "        optimizer = optimizer(model.parameters(), lr=learning_rates, deltaEn = delta_E)\n",
    "    elif isinstance(optimizer(model.parameters(), lr=0.01), SGD):\n",
    "        momentum = trial.suggest_categorical(\"mom\", [0.85, 0.9, 0.95, 0.99, 0.999])\n",
    "        optimizer = optimizer(model.parameters(), lr=learning_rates, momentum = momentum)\n",
    "    else:\n",
    "        weight_decay_values = trial.suggest_categorical(\"wd\", [0, 0.1, 0.3])\n",
    "        optimizer = optimizer(model.parameters(), lr=learning_rates, weight_decay=weight_decay_values)\n",
    "    num_epochs = 3\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sizes, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_sizes, shuffle=True, num_workers=2)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            if isinstance(optimizer, BBI):\n",
    "                def closure():\n",
    "                    return loss\n",
    "                optimizer.step(closure)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:11:20.273044Z",
     "end_time": "2023-04-17T19:11:20.292582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-17 19:11:26,131]\u001B[0m Using an existing study with name 'adam_mnist' instead of creating a new one.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:15:49,368]\u001B[0m Trial 9 finished with value: 92.26 and parameters: {'lr': 0.0001, 'bs': 32, 'wd': 0.1}. Best is trial 7 with value: 97.72.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:21:49,971]\u001B[0m Trial 10 finished with value: 91.8 and parameters: {'lr': 0.01, 'bs': 32, 'wd': 0.1}. Best is trial 7 with value: 97.72.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:27:35,369]\u001B[0m Trial 11 finished with value: 88.16 and parameters: {'lr': 0.0001, 'bs': 32, 'wd': 0.3}. Best is trial 7 with value: 97.72.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs': 128, 'lr': 0.001, 'wd': 0}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(n_startup_trials=115),\n",
    "    pruner=BasePruner,\n",
    "    study_name=\"adam_mnist\",\n",
    "    storage=\"sqlite:///optuna1.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: hyperparameter_search(trial, Adam), n_trials=3)\n",
    "print(study.best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:11:26.014503Z",
     "end_time": "2023-04-17T19:27:35.401985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-17 19:27:35,565]\u001B[0m Using an existing study with name 'adagrad_mnist' instead of creating a new one.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:32:49,171]\u001B[0m Trial 4 finished with value: 67.67 and parameters: {'lr': 0.0001, 'bs': 32, 'wd': 0.1}. Best is trial 1 with value: 91.78.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:37:36,112]\u001B[0m Trial 5 finished with value: 98.34 and parameters: {'lr': 0.01, 'bs': 128, 'wd': 0}. Best is trial 5 with value: 98.34.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:42:42,773]\u001B[0m Trial 6 finished with value: 98.74 and parameters: {'lr': 0.01, 'bs': 32, 'wd': 0}. Best is trial 6 with value: 98.74.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs': 32, 'lr': 0.01, 'wd': 0}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(n_startup_trials=115),\n",
    "    pruner=BasePruner,\n",
    "    study_name=\"adagrad_mnist\",\n",
    "    storage=\"sqlite:///optuna1.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: hyperparameter_search(trial, Adagrad), n_trials=3)\n",
    "print(study.best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:27:35.414011Z",
     "end_time": "2023-04-17T19:42:42.807535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-17 19:42:42,977]\u001B[0m Using an existing study with name 'sgd_mnist1' instead of creating a new one.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:45:53,339]\u001B[0m Trial 4 finished with value: 98.51 and parameters: {'lr': 0.01, 'bs': 64, 'mom': 0.85}. Best is trial 4 with value: 98.51.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:49:18,582]\u001B[0m Trial 5 finished with value: 88.97 and parameters: {'lr': 0.0001, 'bs': 32, 'mom': 0.85}. Best is trial 4 with value: 98.51.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:52:50,243]\u001B[0m Trial 6 finished with value: 88.39 and parameters: {'lr': 0.0001, 'bs': 32, 'mom': 0.85}. Best is trial 4 with value: 98.51.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs': 64, 'lr': 0.01, 'mom': 0.85}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(n_startup_trials=115),\n",
    "    pruner=BasePruner,\n",
    "    study_name=\"sgd_mnist1\",\n",
    "    storage=\"sqlite:///optuna1.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: hyperparameter_search(trial, SGD), n_trials=3)\n",
    "print(study.best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:42:42.820071Z",
     "end_time": "2023-04-17T19:52:50.270692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-17 19:52:50,365]\u001B[0m Using an existing study with name 'bbi_mnist' instead of creating a new one.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 19:57:46,864]\u001B[0m Trial 4 finished with value: 98.19 and parameters: {'lr': 0.01, 'bs': 32, 'delta_e': 0.5}. Best is trial 4 with value: 98.19.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 20:01:37,496]\u001B[0m Trial 5 finished with value: 85.97 and parameters: {'lr': 0.001, 'bs': 32, 'delta_e': 0.1}. Best is trial 4 with value: 98.19.\u001B[0m\n",
      "\u001B[32m[I 2023-04-17 20:05:01,015]\u001B[0m Trial 6 finished with value: 40.36 and parameters: {'lr': 0.001, 'bs': 128, 'delta_e': 1}. Best is trial 4 with value: 98.19.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs': 32, 'delta_e': 0.5, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(n_startup_trials=115),\n",
    "    pruner=BasePruner,\n",
    "    study_name=\"bbi_mnist\",\n",
    "    storage=\"sqlite:///optuna1.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: hyperparameter_search(trial, BBI), n_trials=3)\n",
    "print(study.best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T19:52:50.276827Z",
     "end_time": "2023-04-17T20:05:01.091062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def test(model, optimizer, batch_sizes):\n",
    "    num_epochs = 10\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sizes, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_sizes, shuffle=True, num_workers=2)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            if isinstance(optimizer, BBI):\n",
    "                def closure():\n",
    "                    return loss\n",
    "                optimizer.step(closure)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:06:54.382576Z",
     "end_time": "2023-04-17T20:06:54.401707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.47\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = Adam(model.parameters(), lr = 0.001)\n",
    "print(test(model, optimizer, 128))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:06:56.571722Z",
     "end_time": "2023-04-17T20:10:49.253530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.53\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = Adagrad(model.parameters(), lr = 0.01)\n",
    "print(test(model, optimizer, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:10:49.262943Z",
     "end_time": "2023-04-17T20:14:50.290930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.36\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = SGD(model.parameters(), lr = 0.01, momentum=0.85)\n",
    "print(test(model, optimizer, 64))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:14:50.295929Z",
     "end_time": "2023-04-17T20:18:22.126996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.48\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = BBI(model.parameters(), lr = 0.01, deltaEn=0.5)\n",
    "print(test(model, optimizer, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:18:22.128967Z",
     "end_time": "2023-04-17T20:22:00.443661Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
