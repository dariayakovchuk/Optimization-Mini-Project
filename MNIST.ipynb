{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment of BBI onto MNIST dataset with different architectures.\n",
    "\n",
    "The main idea is to add a one conv layer every time when we launch new check episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from inflation import BBI\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_hidden = 2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # self.fc1 = nn.Linear(in_features=32*7*7, out_features=120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = []\n",
    "        self.layers += [self.conv1, self.relu, self.pool, self.conv2, self.relu]\n",
    "        in_chan = 32\n",
    "        if n_hidden > 2:\n",
    "            for i in range(n_hidden - 2):\n",
    "                self.conv = nn.Conv2d(in_channels=in_chan, out_channels=in_chan*2, kernel_size=3, padding=1)\n",
    "                self.layers += [self.conv, self.relu]\n",
    "                in_chan = in_chan*2\n",
    "        self.layers += [self.pool]\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "        self.fc1 = nn.Linear(in_features=in_chan*7*7, out_features=120)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "\tEpoch 2, \tavrg. loss:  0.06487054339458191\n",
      "\tEpoch 2 \t Accuracy: 98.66\n",
      "\tEpoch 4, \tavrg. loss:  0.03445890884094062\n",
      "\tEpoch 4 \t Accuracy: 98.73\n",
      "\tEpoch 6, \tavrg. loss:  0.02128957494346228\n",
      "\tEpoch 6 \t Accuracy: 99.14\n",
      "\tEpoch 8, \tavrg. loss:  0.012079517182172166\n",
      "\tEpoch 8 \t Accuracy: 99.3\n",
      "\tEpoch 10, \tavrg. loss:  0.008204581163444628\n",
      "\tEpoch 10 \t Accuracy: 99.22\n",
      "Run: 2\n",
      "\tEpoch 2, \tavrg. loss:  0.006128318684501279\n",
      "\tEpoch 2 \t Accuracy: 99.33\n",
      "\tEpoch 4, \tavrg. loss:  0.004351816756905877\n",
      "\tEpoch 4 \t Accuracy: 99.25\n",
      "\tEpoch 6, \tavrg. loss:  0.003268983249184481\n",
      "\tEpoch 6 \t Accuracy: 99.25\n",
      "\tEpoch 8, \tavrg. loss:  0.002425500393307582\n",
      "\tEpoch 8 \t Accuracy: 99.31\n",
      "\tEpoch 10, \tavrg. loss:  0.001961424563659917\n",
      "\tEpoch 10 \t Accuracy: 99.29\n",
      "Run: 3\n",
      "\tEpoch 2, \tavrg. loss:  0.0014574369977934886\n",
      "\tEpoch 2 \t Accuracy: 99.31\n",
      "\tEpoch 4, \tavrg. loss:  0.0011199044864375856\n",
      "\tEpoch 4 \t Accuracy: 99.36\n",
      "\tEpoch 6, \tavrg. loss:  0.000802118777237206\n",
      "\tEpoch 6 \t Accuracy: 99.29\n",
      "\tEpoch 8, \tavrg. loss:  0.0006737221989180078\n",
      "\tEpoch 8 \t Accuracy: 99.3\n",
      "\tEpoch 10, \tavrg. loss:  0.000572729758650233\n",
      "\tEpoch 10 \t Accuracy: 99.34\n",
      "Run: 4\n",
      "\tEpoch 2, \tavrg. loss:  0.0004613010565630714\n",
      "\tEpoch 2 \t Accuracy: 99.3\n",
      "\tEpoch 4, \tavrg. loss:  0.00030239715408613424\n",
      "\tEpoch 4 \t Accuracy: 99.27\n",
      "\tEpoch 6, \tavrg. loss:  0.0002141967300359976\n",
      "\tEpoch 6 \t Accuracy: 99.29\n",
      "\tEpoch 8, \tavrg. loss:  4.494263803382628e-05\n",
      "\tEpoch 8 \t Accuracy: 99.3\n",
      "\tEpoch 10, \tavrg. loss:  8.072446112815773e-06\n",
      "\tEpoch 10 \t Accuracy: 99.3\n",
      "Run: 5\n",
      "\tEpoch 2, \tavrg. loss:  1.7623508246852579e-06\n",
      "\tEpoch 2 \t Accuracy: 99.26\n",
      "\tEpoch 4, \tavrg. loss:  1.5643967532626545e-06\n",
      "\tEpoch 4 \t Accuracy: 99.28\n",
      "\tEpoch 6, \tavrg. loss:  1.6508229144932843e-06\n",
      "\tEpoch 6 \t Accuracy: 99.25\n",
      "\tEpoch 8, \tavrg. loss:  9.916059650750229e-07\n",
      "\tEpoch 8 \t Accuracy: 99.26\n",
      "\tEpoch 10, \tavrg. loss:  1.0118590011765782e-06\n",
      "\tEpoch 10 \t Accuracy: 99.28\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = Net(2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "v0 = 1e-6\n",
    "threshold0 = 100\n",
    "n_fixed_bounces = 5\n",
    "threshold = 1000\n",
    "n_check = 5\n",
    "\n",
    "optimizer = BBI(model.parameters(), lr=0.2, deltaEn = 1.0, v0 = v0, threshold0 = threshold0, threshold = threshold, n_fixed_bounces = n_fixed_bounces)\n",
    "\n",
    "tests_loss = []\n",
    "for k in range(n_check):\n",
    "    print(f'Run: {k+1}')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss_tr = 0.0\n",
    "        test = []\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            def closure(): return loss \n",
    "            optimizer.step(closure)\n",
    "            loss_tr += loss.item()\n",
    "        \n",
    "        if epoch%2 == 0: print(f'\\tEpoch {epoch}, \\tavrg. loss: ', loss_tr / len(train_loader))\n",
    "        tests_loss.append(loss_tr / len(train_loader))\n",
    "\n",
    "        # Evaluate for each epoch\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if epoch%2 == 0: print(f'\\tEpoch {epoch} \\t Accuracy: {100 * correct / total}')\n",
    "        test.append(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1 \t# of conv. layers: 2\n",
      "\tEpoch 2, \tavrg. loss:  0.06426373033595124\n",
      "\tEpoch 2 \t Accuracy: 98.17\n",
      "\tEpoch 4, \tavrg. loss:  0.03698173857828651\n",
      "\tEpoch 4 \t Accuracy: 98.73\n",
      "\tEpoch 6, \tavrg. loss:  0.0230199791727534\n",
      "\tEpoch 6 \t Accuracy: 98.94\n",
      "\tEpoch 8, \tavrg. loss:  0.014104531379921539\n",
      "\tEpoch 8 \t Accuracy: 99.1\n",
      "\tEpoch 10, \tavrg. loss:  0.009323428860247911\n",
      "\tEpoch 10 \t Accuracy: 99.21\n",
      "Run: 2 \t# of conv. layers: 3\n",
      "\tEpoch 2, \tavrg. loss:  0.20045167263741218\n",
      "\tEpoch 2 \t Accuracy: 96.38\n",
      "\tEpoch 4, \tavrg. loss:  0.12813482028586087\n",
      "\tEpoch 4 \t Accuracy: 96.98\n",
      "\tEpoch 6, \tavrg. loss:  0.1080849361621456\n",
      "\tEpoch 6 \t Accuracy: 97.23\n",
      "\tEpoch 8, \tavrg. loss:  0.07746171416398585\n",
      "\tEpoch 8 \t Accuracy: 98.14\n",
      "\tEpoch 10, \tavrg. loss:  0.06148562432722836\n",
      "\tEpoch 10 \t Accuracy: 98.23\n",
      "Run: 3 \t# of conv. layers: 4\n",
      "\tEpoch 2, \tavrg. loss:  0.192361464625153\n",
      "\tEpoch 2 \t Accuracy: 93.67\n",
      "\tEpoch 4, \tavrg. loss:  0.165458896091885\n",
      "\tEpoch 4 \t Accuracy: 95.82\n",
      "\tEpoch 6, \tavrg. loss:  0.1329773786633627\n",
      "\tEpoch 6 \t Accuracy: 97.28\n",
      "\tEpoch 8, \tavrg. loss:  0.1084661874979082\n",
      "\tEpoch 8 \t Accuracy: 96.59\n",
      "\tEpoch 10, \tavrg. loss:  0.09080129685427701\n",
      "\tEpoch 10 \t Accuracy: 97.5\n",
      "Run: 4 \t# of conv. layers: 5\n",
      "\tEpoch 2, \tavrg. loss:  2.4046105929275057\n",
      "\tEpoch 2 \t Accuracy: 10.28\n",
      "\tEpoch 4, \tavrg. loss:  2.340261639562497\n",
      "\tEpoch 4 \t Accuracy: 9.82\n",
      "\tEpoch 6, \tavrg. loss:  2.3720499526208907\n",
      "\tEpoch 6 \t Accuracy: 9.8\n",
      "\tEpoch 8, \tavrg. loss:  nan\n",
      "\tEpoch 8 \t Accuracy: 9.8\n",
      "\tEpoch 10, \tavrg. loss:  nan\n",
      "\tEpoch 10 \t Accuracy: 9.8\n",
      "Run: 5 \t# of conv. layers: 6\n",
      "\tEpoch 2, \tavrg. loss:  2.5971626289871965\n",
      "\tEpoch 2 \t Accuracy: 9.82\n",
      "\tEpoch 4, \tavrg. loss:  3.0521331745932607\n",
      "\tEpoch 4 \t Accuracy: 9.8\n",
      "\tEpoch 6, \tavrg. loss:  3.1430232537580705\n",
      "\tEpoch 6 \t Accuracy: 10.32\n",
      "\tEpoch 8, \tavrg. loss:  2.815352064205894\n",
      "\tEpoch 8 \t Accuracy: 9.82\n",
      "\tEpoch 10, \tavrg. loss:  2.3444577025960505\n",
      "\tEpoch 10 \t Accuracy: 10.1\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "epochs = 10\n",
    "v0 = 1e-6\n",
    "threshold0 = 100\n",
    "n_fixed_bounces = 5\n",
    "threshold = 1000\n",
    "n_check = 5\n",
    "tests_loss_new = []\n",
    "for k in range(n_check):\n",
    "    print(f'Run: {k+1} \\t# of conv. layers: {2+k}')\n",
    "    model = Net(2 + k).to(device)\n",
    "    optimizer = BBI(model.parameters(), lr=0.2, deltaEn = 1.0, v0 = v0, threshold0 = threshold0, threshold = threshold, n_fixed_bounces = n_fixed_bounces)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss_tr = 0.0\n",
    "        test = []\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            def closure(): return loss \n",
    "            optimizer.step(closure)\n",
    "            loss_tr += loss.item()\n",
    "        if epoch%2 == 0: print(f'\\tEpoch {epoch}, \\tavrg. loss: ', loss_tr / len(train_loader))\n",
    "        tests_loss_new.append(loss_tr / len(train_loader))\n",
    "\n",
    "        # Evaluate\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        if epoch%2 == 0: print(f'\\tEpoch {epoch} \\t Accuracy: {100 * correct / total}')\n",
    "        test.append(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1 \t# of conv. layers: 2\n",
      "Run: 2 \t# of conv. layers: 3\n",
      "Run: 3 \t# of conv. layers: 4\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "epochs = 5\n",
    "v0 = 1e-6\n",
    "threshold0 = 100\n",
    "n_fixed_bounces = 5\n",
    "threshold = 1000\n",
    "n_check = 6\n",
    "test_loss_BBI = []\n",
    "for k in range(n_check):\n",
    "    print(f'Run: {k+1} \\t# of conv. layers: {2+k}')\n",
    "    model = Net(2 + k).to(device)\n",
    "    optimizer = BBI(model.parameters(), lr=0.2, deltaEn = 1.0, v0 = v0, threshold0 = threshold0, threshold = threshold, n_fixed_bounces = n_fixed_bounces)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss_tr = 0.0\n",
    "        test = []\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            def closure(): return loss \n",
    "            optimizer.step(closure)\n",
    "            loss_tr += loss.item()\n",
    "    \n",
    "    # Evaluate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss_BBI.append(loss)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test.append(correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
